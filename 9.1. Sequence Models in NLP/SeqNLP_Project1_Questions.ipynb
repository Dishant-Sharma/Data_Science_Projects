{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xT7MKZuMRaCg"
   },
   "source": [
    "# Sentiment Classification\n",
    "\n",
    "\n",
    "### Generate Word Embeddings and retrieve outputs of each layer with Keras based on Classification task\n",
    "\n",
    "Word embeddings are a type of word representation that allows words with similar meaning to have a similar representation.\n",
    "\n",
    "It is a distributed representation for text that is perhaps one of the key breakthroughs for the impressive performance of deep learning methods on challenging natural language processing problems.\n",
    "\n",
    "We willl use the imdb dataset to learn word embeddings as we train our dataset. This dataset contains 25,000 movie reviews from IMDB, labeled with sentiment (positive or negative). \n",
    "\n",
    "\n",
    "\n",
    "### Dataset\n",
    "\n",
    "`from keras.datasets import imdb`\n",
    "\n",
    "Dataset of 25,000 movies reviews from IMDB, labeled by sentiment (positive/negative). Reviews have been preprocessed, and each review is encoded as a sequence of word indexes (integers). For convenience, the words are indexed by their frequency in the dataset, meaning the for that has index 1 is the most frequent word. Use the first 20 words from each review to speed up training, using a max vocab size of 10,000.\n",
    "\n",
    "As a convention, \"0\" does not stand for a specific word, but instead is used to encode any unknown word.\n",
    "\n",
    "\n",
    "### Aim\n",
    "\n",
    "1. Import test and train data  \n",
    "2. Import the labels ( train and test) \n",
    "3. Get the word index and then Create key value pair for word and word_id. (12.5 points)\n",
    "4. Build a Sequential Model using Keras for Sentiment Classification task. (10 points)\n",
    "5. Report the Accuracy of the model. (5 points)  \n",
    "6. Retrive the output of each layer in keras for a given single test sample from the trained model you built. (2.5 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wq4RCyyPSYRp"
   },
   "source": [
    "#### Usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I25y73Z9L9BZ"
   },
   "outputs": [],
   "source": [
    "#1.Import test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "51d5ZH6OKtlK",
    "outputId": "85b3eb4a-dbb8-4ad0-e30f-fa9b841d0d75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.16.2 in /usr/local/lib/python2.7/dist-packages (1.16.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.16.2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "colab_type": "code",
    "id": "NGCtiXUhSWss",
    "outputId": "af5b8977-8f88-4fda-b166-eb1930c99bd4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "\n",
    "vocab_size = 10000 #vocab size\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size) # vocab_size is no.of words to consider from the dataset, ordering based on frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fCPC_WN-eCyw"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "vocab_size = 10000 #vocab size\n",
    "maxlen = 300  #number of word used from each review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8-x-VuYnMBZ8"
   },
   "outputs": [],
   "source": [
    "#2. Import the labels ( train and test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h0g381XzeCyz"
   },
   "outputs": [],
   "source": [
    "#load dataset as a list of ints\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
    "#make all sequences of the same length\n",
    "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test =  pad_sequences(x_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "Jy6n-uM2eCy2",
    "outputId": "8b25bbab-bc9a-40eb-db03-67ae37fc3ed9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('x_train shape: ', (25000, 300))\n",
      "('y_train shape: ', (25000,))\n",
      "('x_test shape: ', (25000, 300))\n",
      "('y_test shape: ', (25000,))\n"
     ]
    }
   ],
   "source": [
    "print (\"x_train shape: \", x_train.shape)\n",
    "print (\"y_train shape: \", y_train.shape)\n",
    "print (\"x_test shape: \", x_test.shape)\n",
    "print (\"y_test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "tZhMAgaNeCy5",
    "outputId": "1cfe49c1-7355-4132-f5ee-cb7e5227b86c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum value of a word index \n",
      "9999\n",
      "Maximum length num words of review in train \n",
      "300\n"
     ]
    }
   ],
   "source": [
    "print(\"Maximum value of a word index \")\n",
    "print(max([max(sequence) for sequence in x_train]))\n",
    "print(\"Maximum length num words of review in train \")\n",
    "print(max([len(sequence) for sequence in x_train]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e1IxKtSKOwUG"
   },
   "outputs": [],
   "source": [
    "#3.Get the word index and then Create key value pair for word and word_id. (12.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2WK49JoBOw7D"
   },
   "outputs": [],
   "source": [
    "# Make Word to ID dictionary\n",
    "INDEX_FROM=3   # word index offset\n",
    "word_to_id = imdb.get_word_index() #Get the word index\n",
    "word_to_id = {k:(v+INDEX_FROM) for k,v in word_to_id.items()}\n",
    "\n",
    "word_to_id[\"<PAD>\"] = 0\n",
    "\n",
    "word_to_id[\"<START>\"] = 1\n",
    "\n",
    "word_to_id[\"<UNK>\"] = 2\n",
    "\n",
    "# Make ID to Word dictionary\n",
    "id_to_word = {value:key for key,value in word_to_id.items()}\n",
    "\n",
    "def restore_original_text(imdb_x_array):\n",
    "    return (' '.join(id_to_word[id] for id in imdb_x_array ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "naAsA4m_WULJ",
    "outputId": "31176320-b3c6-4a72-c5f0-eb819030f451"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '<PAD>',\n",
       " 1: '<START>',\n",
       " 2: '<UNK>',\n",
       " 4: u'the',\n",
       " 5: u'and',\n",
       " 6: u'a',\n",
       " 7: u'of',\n",
       " 8: u'to',\n",
       " 9: u'is',\n",
       " 10: u'br',\n",
       " 11: u'in',\n",
       " 12: u'it',\n",
       " 13: u'i',\n",
       " 14: u'this',\n",
       " 15: u'that',\n",
       " 16: u'was',\n",
       " 17: u'as',\n",
       " 18: u'for',\n",
       " 19: u'with',\n",
       " 20: u'movie',\n",
       " 21: u'but',\n",
       " 22: u'film',\n",
       " 23: u'on',\n",
       " 24: u'not',\n",
       " 25: u'you',\n",
       " 26: u'are',\n",
       " 27: u'his',\n",
       " 28: u'have',\n",
       " 29: u'he',\n",
       " 30: u'be',\n",
       " 31: u'one',\n",
       " 32: u'all',\n",
       " 33: u'at',\n",
       " 34: u'by',\n",
       " 35: u'an',\n",
       " 36: u'they',\n",
       " 37: u'who',\n",
       " 38: u'so',\n",
       " 39: u'from',\n",
       " 40: u'like',\n",
       " 41: u'her',\n",
       " 42: u'or',\n",
       " 43: u'just',\n",
       " 44: u'about',\n",
       " 45: u\"it's\",\n",
       " 46: u'out',\n",
       " 47: u'has',\n",
       " 48: u'if',\n",
       " 49: u'some',\n",
       " 50: u'there',\n",
       " 51: u'what',\n",
       " 52: u'good',\n",
       " 53: u'more',\n",
       " 54: u'when',\n",
       " 55: u'very',\n",
       " 56: u'up',\n",
       " 57: u'no',\n",
       " 58: u'time',\n",
       " 59: u'she',\n",
       " 60: u'even',\n",
       " 61: u'my',\n",
       " 62: u'would',\n",
       " 63: u'which',\n",
       " 64: u'only',\n",
       " 65: u'story',\n",
       " 66: u'really',\n",
       " 67: u'see',\n",
       " 68: u'their',\n",
       " 69: u'had',\n",
       " 70: u'can',\n",
       " 71: u'were',\n",
       " 72: u'me',\n",
       " 73: u'well',\n",
       " 74: u'than',\n",
       " 75: u'we',\n",
       " 76: u'much',\n",
       " 77: u'been',\n",
       " 78: u'bad',\n",
       " 79: u'get',\n",
       " 80: u'will',\n",
       " 81: u'do',\n",
       " 82: u'also',\n",
       " 83: u'into',\n",
       " 84: u'people',\n",
       " 85: u'other',\n",
       " 86: u'first',\n",
       " 87: u'great',\n",
       " 88: u'because',\n",
       " 89: u'how',\n",
       " 90: u'him',\n",
       " 91: u'most',\n",
       " 92: u\"don't\",\n",
       " 93: u'made',\n",
       " 94: u'its',\n",
       " 95: u'then',\n",
       " 96: u'way',\n",
       " 97: u'make',\n",
       " 98: u'them',\n",
       " 99: u'too',\n",
       " 100: u'could',\n",
       " 101: u'any',\n",
       " 102: u'movies',\n",
       " 103: u'after',\n",
       " 104: u'think',\n",
       " 105: u'characters',\n",
       " 106: u'watch',\n",
       " 107: u'two',\n",
       " 108: u'films',\n",
       " 109: u'character',\n",
       " 110: u'seen',\n",
       " 111: u'many',\n",
       " 112: u'being',\n",
       " 113: u'life',\n",
       " 114: u'plot',\n",
       " 115: u'never',\n",
       " 116: u'acting',\n",
       " 117: u'little',\n",
       " 118: u'best',\n",
       " 119: u'love',\n",
       " 120: u'over',\n",
       " 121: u'where',\n",
       " 122: u'did',\n",
       " 123: u'show',\n",
       " 124: u'know',\n",
       " 125: u'off',\n",
       " 126: u'ever',\n",
       " 127: u'does',\n",
       " 128: u'better',\n",
       " 129: u'your',\n",
       " 130: u'end',\n",
       " 131: u'still',\n",
       " 132: u'man',\n",
       " 133: u'here',\n",
       " 134: u'these',\n",
       " 135: u'say',\n",
       " 136: u'scene',\n",
       " 137: u'while',\n",
       " 138: u'why',\n",
       " 139: u'scenes',\n",
       " 140: u'go',\n",
       " 141: u'such',\n",
       " 142: u'something',\n",
       " 143: u'through',\n",
       " 144: u'should',\n",
       " 145: u'back',\n",
       " 146: u\"i'm\",\n",
       " 147: u'real',\n",
       " 148: u'those',\n",
       " 149: u'watching',\n",
       " 150: u'now',\n",
       " 151: u'though',\n",
       " 152: u\"doesn't\",\n",
       " 153: u'years',\n",
       " 154: u'old',\n",
       " 155: u'thing',\n",
       " 156: u'actors',\n",
       " 157: u'work',\n",
       " 158: u'10',\n",
       " 159: u'before',\n",
       " 160: u'another',\n",
       " 161: u\"didn't\",\n",
       " 162: u'new',\n",
       " 163: u'funny',\n",
       " 164: u'nothing',\n",
       " 165: u'actually',\n",
       " 166: u'makes',\n",
       " 167: u'director',\n",
       " 168: u'look',\n",
       " 169: u'find',\n",
       " 170: u'going',\n",
       " 171: u'few',\n",
       " 172: u'same',\n",
       " 173: u'part',\n",
       " 174: u'again',\n",
       " 175: u'every',\n",
       " 176: u'lot',\n",
       " 177: u'cast',\n",
       " 178: u'us',\n",
       " 179: u'quite',\n",
       " 180: u'down',\n",
       " 181: u'want',\n",
       " 182: u'world',\n",
       " 183: u'things',\n",
       " 184: u'pretty',\n",
       " 185: u'young',\n",
       " 186: u'seems',\n",
       " 187: u'around',\n",
       " 188: u'got',\n",
       " 189: u'horror',\n",
       " 190: u'however',\n",
       " 191: u\"can't\",\n",
       " 192: u'fact',\n",
       " 193: u'take',\n",
       " 194: u'big',\n",
       " 195: u'enough',\n",
       " 196: u'long',\n",
       " 197: u'thought',\n",
       " 198: u\"that's\",\n",
       " 199: u'both',\n",
       " 200: u'between',\n",
       " 201: u'series',\n",
       " 202: u'give',\n",
       " 203: u'may',\n",
       " 204: u'original',\n",
       " 205: u'own',\n",
       " 206: u'action',\n",
       " 207: u\"i've\",\n",
       " 208: u'right',\n",
       " 209: u'without',\n",
       " 210: u'always',\n",
       " 211: u'times',\n",
       " 212: u'comedy',\n",
       " 213: u'point',\n",
       " 214: u'gets',\n",
       " 215: u'must',\n",
       " 216: u'come',\n",
       " 217: u'role',\n",
       " 218: u\"isn't\",\n",
       " 219: u'saw',\n",
       " 220: u'almost',\n",
       " 221: u'interesting',\n",
       " 222: u'least',\n",
       " 223: u'family',\n",
       " 224: u'done',\n",
       " 225: u\"there's\",\n",
       " 226: u'whole',\n",
       " 227: u'bit',\n",
       " 228: u'music',\n",
       " 229: u'script',\n",
       " 230: u'far',\n",
       " 231: u'making',\n",
       " 232: u'guy',\n",
       " 233: u'anything',\n",
       " 234: u'minutes',\n",
       " 235: u'feel',\n",
       " 236: u'last',\n",
       " 237: u'since',\n",
       " 238: u'might',\n",
       " 239: u'performance',\n",
       " 240: u\"he's\",\n",
       " 241: u'2',\n",
       " 242: u'probably',\n",
       " 243: u'kind',\n",
       " 244: u'am',\n",
       " 245: u'away',\n",
       " 246: u'yet',\n",
       " 247: u'rather',\n",
       " 248: u'tv',\n",
       " 249: u'worst',\n",
       " 250: u'girl',\n",
       " 251: u'day',\n",
       " 252: u'sure',\n",
       " 253: u'fun',\n",
       " 254: u'hard',\n",
       " 255: u'woman',\n",
       " 256: u'played',\n",
       " 257: u'each',\n",
       " 258: u'found',\n",
       " 259: u'anyone',\n",
       " 260: u'having',\n",
       " 261: u'although',\n",
       " 262: u'especially',\n",
       " 263: u'our',\n",
       " 264: u'believe',\n",
       " 265: u'course',\n",
       " 266: u'comes',\n",
       " 267: u'looking',\n",
       " 268: u'screen',\n",
       " 269: u'trying',\n",
       " 270: u'set',\n",
       " 271: u'goes',\n",
       " 272: u'looks',\n",
       " 273: u'place',\n",
       " 274: u'book',\n",
       " 275: u'different',\n",
       " 276: u'put',\n",
       " 277: u'ending',\n",
       " 278: u'money',\n",
       " 279: u'maybe',\n",
       " 280: u'once',\n",
       " 281: u'sense',\n",
       " 282: u'reason',\n",
       " 283: u'true',\n",
       " 284: u'actor',\n",
       " 285: u'everything',\n",
       " 286: u\"wasn't\",\n",
       " 287: u'shows',\n",
       " 288: u'dvd',\n",
       " 289: u'three',\n",
       " 290: u'worth',\n",
       " 291: u'year',\n",
       " 292: u'job',\n",
       " 293: u'main',\n",
       " 294: u'someone',\n",
       " 295: u'together',\n",
       " 296: u'watched',\n",
       " 297: u'play',\n",
       " 298: u'american',\n",
       " 299: u'plays',\n",
       " 300: u'1',\n",
       " 301: u'said',\n",
       " 302: u'effects',\n",
       " 303: u'later',\n",
       " 304: u'takes',\n",
       " 305: u'instead',\n",
       " 306: u'seem',\n",
       " 307: u'beautiful',\n",
       " 308: u'john',\n",
       " 309: u'himself',\n",
       " 310: u'version',\n",
       " 311: u'audience',\n",
       " 312: u'high',\n",
       " 313: u'house',\n",
       " 314: u'night',\n",
       " 315: u'during',\n",
       " 316: u'everyone',\n",
       " 317: u'left',\n",
       " 318: u'special',\n",
       " 319: u'seeing',\n",
       " 320: u'half',\n",
       " 321: u'excellent',\n",
       " 322: u'wife',\n",
       " 323: u'star',\n",
       " 324: u'shot',\n",
       " 325: u'war',\n",
       " 326: u'idea',\n",
       " 327: u'nice',\n",
       " 328: u'black',\n",
       " 329: u'less',\n",
       " 330: u'mind',\n",
       " 331: u'simply',\n",
       " 332: u'read',\n",
       " 333: u'second',\n",
       " 334: u'else',\n",
       " 335: u\"you're\",\n",
       " 336: u'father',\n",
       " 337: u'fan',\n",
       " 338: u'poor',\n",
       " 339: u'help',\n",
       " 340: u'completely',\n",
       " 341: u'death',\n",
       " 342: u'3',\n",
       " 343: u'used',\n",
       " 344: u'home',\n",
       " 345: u'either',\n",
       " 346: u'short',\n",
       " 347: u'line',\n",
       " 348: u'given',\n",
       " 349: u'men',\n",
       " 350: u'top',\n",
       " 351: u'dead',\n",
       " 352: u'budget',\n",
       " 353: u'try',\n",
       " 354: u'performances',\n",
       " 355: u'wrong',\n",
       " 356: u'classic',\n",
       " 357: u'boring',\n",
       " 358: u'enjoy',\n",
       " 359: u'need',\n",
       " 360: u'rest',\n",
       " 361: u'use',\n",
       " 362: u'kids',\n",
       " 363: u'hollywood',\n",
       " 364: u'low',\n",
       " 365: u'production',\n",
       " 366: u'until',\n",
       " 367: u'along',\n",
       " 368: u'full',\n",
       " 369: u'friends',\n",
       " 370: u'camera',\n",
       " 371: u'truly',\n",
       " 372: u'women',\n",
       " 373: u'awful',\n",
       " 374: u'video',\n",
       " 375: u'next',\n",
       " 376: u'tell',\n",
       " 377: u'remember',\n",
       " 378: u'couple',\n",
       " 379: u'stupid',\n",
       " 380: u'start',\n",
       " 381: u'stars',\n",
       " 382: u'perhaps',\n",
       " 383: u'sex',\n",
       " 384: u'mean',\n",
       " 385: u'came',\n",
       " 386: u'recommend',\n",
       " 387: u'let',\n",
       " 388: u'moments',\n",
       " 389: u'wonderful',\n",
       " 390: u'episode',\n",
       " 391: u'understand',\n",
       " 392: u'small',\n",
       " 393: u'face',\n",
       " 394: u'terrible',\n",
       " 395: u'playing',\n",
       " 396: u'school',\n",
       " 397: u'getting',\n",
       " 398: u'written',\n",
       " 399: u'doing',\n",
       " 400: u'often',\n",
       " 401: u'keep',\n",
       " 402: u'early',\n",
       " 403: u'name',\n",
       " 404: u'perfect',\n",
       " 405: u'style',\n",
       " 406: u'human',\n",
       " 407: u'definitely',\n",
       " 408: u'gives',\n",
       " 409: u'others',\n",
       " 410: u'itself',\n",
       " 411: u'lines',\n",
       " 412: u'live',\n",
       " 413: u'become',\n",
       " 414: u'dialogue',\n",
       " 415: u'person',\n",
       " 416: u'lost',\n",
       " 417: u'finally',\n",
       " 418: u'piece',\n",
       " 419: u'head',\n",
       " 420: u'case',\n",
       " 421: u'felt',\n",
       " 422: u'yes',\n",
       " 423: u'liked',\n",
       " 424: u'supposed',\n",
       " 425: u'title',\n",
       " 426: u\"couldn't\",\n",
       " 427: u'absolutely',\n",
       " 428: u'white',\n",
       " 429: u'against',\n",
       " 430: u'boy',\n",
       " 431: u'picture',\n",
       " 432: u'sort',\n",
       " 433: u'worse',\n",
       " 434: u'certainly',\n",
       " 435: u'went',\n",
       " 436: u'entire',\n",
       " 437: u'waste',\n",
       " 438: u'cinema',\n",
       " 439: u'problem',\n",
       " 440: u'hope',\n",
       " 441: u'entertaining',\n",
       " 442: u\"she's\",\n",
       " 443: u'mr',\n",
       " 444: u'overall',\n",
       " 445: u'evil',\n",
       " 446: u'called',\n",
       " 447: u'loved',\n",
       " 448: u'based',\n",
       " 449: u'oh',\n",
       " 450: u'several',\n",
       " 451: u'fans',\n",
       " 452: u'mother',\n",
       " 453: u'drama',\n",
       " 454: u'beginning',\n",
       " 455: u'killer',\n",
       " 456: u'lives',\n",
       " 457: u'5',\n",
       " 458: u'direction',\n",
       " 459: u'care',\n",
       " 460: u'already',\n",
       " 461: u'becomes',\n",
       " 462: u'laugh',\n",
       " 463: u'example',\n",
       " 464: u'friend',\n",
       " 465: u'dark',\n",
       " 466: u'despite',\n",
       " 467: u'under',\n",
       " 468: u'seemed',\n",
       " 469: u'throughout',\n",
       " 470: u'4',\n",
       " 471: u'turn',\n",
       " 472: u'unfortunately',\n",
       " 473: u'wanted',\n",
       " 474: u\"i'd\",\n",
       " 475: u'\\x96',\n",
       " 476: u'children',\n",
       " 477: u'final',\n",
       " 478: u'fine',\n",
       " 479: u'history',\n",
       " 480: u'amazing',\n",
       " 481: u'sound',\n",
       " 482: u'guess',\n",
       " 483: u'heart',\n",
       " 484: u'totally',\n",
       " 485: u'lead',\n",
       " 486: u'humor',\n",
       " 487: u'writing',\n",
       " 488: u'michael',\n",
       " 489: u'quality',\n",
       " 490: u\"you'll\",\n",
       " 491: u'close',\n",
       " 492: u'son',\n",
       " 493: u'guys',\n",
       " 494: u'wants',\n",
       " 495: u'works',\n",
       " 496: u'behind',\n",
       " 497: u'tries',\n",
       " 498: u'art',\n",
       " 499: u'side',\n",
       " 500: u'game',\n",
       " 501: u'past',\n",
       " 502: u'able',\n",
       " 503: u'b',\n",
       " 504: u'days',\n",
       " 505: u'turns',\n",
       " 506: u'child',\n",
       " 507: u\"they're\",\n",
       " 508: u'hand',\n",
       " 509: u'flick',\n",
       " 510: u'enjoyed',\n",
       " 511: u'act',\n",
       " 512: u'genre',\n",
       " 513: u'town',\n",
       " 514: u'favorite',\n",
       " 515: u'soon',\n",
       " 516: u'kill',\n",
       " 517: u'starts',\n",
       " 518: u'sometimes',\n",
       " 519: u'car',\n",
       " 520: u'gave',\n",
       " 521: u'run',\n",
       " 522: u'late',\n",
       " 523: u'eyes',\n",
       " 524: u'actress',\n",
       " 525: u'etc',\n",
       " 526: u'directed',\n",
       " 527: u'horrible',\n",
       " 528: u\"won't\",\n",
       " 529: u'viewer',\n",
       " 530: u'brilliant',\n",
       " 531: u'parts',\n",
       " 532: u'self',\n",
       " 533: u'themselves',\n",
       " 534: u'hour',\n",
       " 535: u'expect',\n",
       " 536: u'thinking',\n",
       " 537: u'stories',\n",
       " 538: u'stuff',\n",
       " 539: u'girls',\n",
       " 540: u'obviously',\n",
       " 541: u'blood',\n",
       " 542: u'decent',\n",
       " 543: u'city',\n",
       " 544: u'voice',\n",
       " 545: u'highly',\n",
       " 546: u'myself',\n",
       " 547: u'feeling',\n",
       " 548: u'fight',\n",
       " 549: u'except',\n",
       " 550: u'slow',\n",
       " 551: u'matter',\n",
       " 552: u'type',\n",
       " 553: u'anyway',\n",
       " 554: u'kid',\n",
       " 555: u'roles',\n",
       " 556: u'killed',\n",
       " 557: u'heard',\n",
       " 558: u'god',\n",
       " 559: u'age',\n",
       " 560: u'says',\n",
       " 561: u'moment',\n",
       " 562: u'took',\n",
       " 563: u'leave',\n",
       " 564: u'writer',\n",
       " 565: u'strong',\n",
       " 566: u'cannot',\n",
       " 567: u'violence',\n",
       " 568: u'police',\n",
       " 569: u'hit',\n",
       " 570: u'stop',\n",
       " 571: u'happens',\n",
       " 572: u'particularly',\n",
       " 573: u'known',\n",
       " 574: u'involved',\n",
       " 575: u'happened',\n",
       " 576: u'extremely',\n",
       " 577: u'daughter',\n",
       " 578: u'obvious',\n",
       " 579: u'told',\n",
       " 580: u'chance',\n",
       " 581: u'living',\n",
       " 582: u'coming',\n",
       " 583: u'lack',\n",
       " 584: u'alone',\n",
       " 585: u'experience',\n",
       " 586: u\"wouldn't\",\n",
       " 587: u'including',\n",
       " 588: u'murder',\n",
       " 589: u'attempt',\n",
       " 590: u's',\n",
       " 591: u'please',\n",
       " 592: u'james',\n",
       " 593: u'happen',\n",
       " 594: u'wonder',\n",
       " 595: u'crap',\n",
       " 596: u'ago',\n",
       " 597: u'brother',\n",
       " 598: u\"film's\",\n",
       " 599: u'gore',\n",
       " 600: u'none',\n",
       " 601: u'complete',\n",
       " 602: u'interest',\n",
       " 603: u'score',\n",
       " 604: u'group',\n",
       " 605: u'cut',\n",
       " 606: u'simple',\n",
       " 607: u'save',\n",
       " 608: u'ok',\n",
       " 609: u'hell',\n",
       " 610: u'looked',\n",
       " 611: u'career',\n",
       " 612: u'number',\n",
       " 613: u'song',\n",
       " 614: u'possible',\n",
       " 615: u'seriously',\n",
       " 616: u'annoying',\n",
       " 617: u'shown',\n",
       " 618: u'exactly',\n",
       " 619: u'sad',\n",
       " 620: u'running',\n",
       " 621: u'musical',\n",
       " 622: u'serious',\n",
       " 623: u'taken',\n",
       " 624: u'yourself',\n",
       " 625: u'whose',\n",
       " 626: u'released',\n",
       " 627: u'cinematography',\n",
       " 628: u'david',\n",
       " 629: u'scary',\n",
       " 630: u'ends',\n",
       " 631: u'english',\n",
       " 632: u'hero',\n",
       " 633: u'usually',\n",
       " 634: u'hours',\n",
       " 635: u'reality',\n",
       " 636: u'opening',\n",
       " 637: u\"i'll\",\n",
       " 638: u'across',\n",
       " 639: u'today',\n",
       " 640: u'jokes',\n",
       " 641: u'light',\n",
       " 642: u'hilarious',\n",
       " 643: u'somewhat',\n",
       " 644: u'usual',\n",
       " 645: u'started',\n",
       " 646: u'cool',\n",
       " 647: u'ridiculous',\n",
       " 648: u'body',\n",
       " 649: u'relationship',\n",
       " 650: u'view',\n",
       " 651: u'level',\n",
       " 652: u'opinion',\n",
       " 653: u'change',\n",
       " 654: u'happy',\n",
       " 655: u'middle',\n",
       " 656: u'taking',\n",
       " 657: u'wish',\n",
       " 658: u'husband',\n",
       " 659: u'finds',\n",
       " 660: u'saying',\n",
       " 661: u'order',\n",
       " 662: u'talking',\n",
       " 663: u'ones',\n",
       " 664: u'documentary',\n",
       " 665: u'shots',\n",
       " 666: u'huge',\n",
       " 667: u'novel',\n",
       " 668: u'female',\n",
       " 669: u'mostly',\n",
       " 670: u'robert',\n",
       " 671: u'power',\n",
       " 672: u'episodes',\n",
       " 673: u'room',\n",
       " 674: u'important',\n",
       " 675: u'rating',\n",
       " 676: u'talent',\n",
       " 677: u'five',\n",
       " 678: u'major',\n",
       " 679: u'turned',\n",
       " 680: u'strange',\n",
       " 681: u'word',\n",
       " 682: u'modern',\n",
       " 683: u'call',\n",
       " 684: u'apparently',\n",
       " 685: u'disappointed',\n",
       " 686: u'single',\n",
       " 687: u'events',\n",
       " 688: u'due',\n",
       " 689: u'four',\n",
       " 690: u'songs',\n",
       " 691: u'basically',\n",
       " 692: u'attention',\n",
       " 693: u'7',\n",
       " 694: u'knows',\n",
       " 695: u'clearly',\n",
       " 696: u'supporting',\n",
       " 697: u'knew',\n",
       " 698: u'british',\n",
       " 699: u'television',\n",
       " 700: u'comic',\n",
       " 701: u'non',\n",
       " 702: u'fast',\n",
       " 703: u'earth',\n",
       " 704: u'country',\n",
       " 705: u'future',\n",
       " 706: u'cheap',\n",
       " 707: u'class',\n",
       " 708: u'thriller',\n",
       " 709: u'8',\n",
       " 710: u'silly',\n",
       " 711: u'king',\n",
       " 712: u'problems',\n",
       " 713: u\"aren't\",\n",
       " 714: u'easily',\n",
       " 715: u'words',\n",
       " 716: u'tells',\n",
       " 717: u'miss',\n",
       " 718: u'jack',\n",
       " 719: u'local',\n",
       " 720: u'sequence',\n",
       " 721: u'bring',\n",
       " 722: u'entertainment',\n",
       " 723: u'paul',\n",
       " 724: u'beyond',\n",
       " 725: u'upon',\n",
       " 726: u'whether',\n",
       " 727: u'predictable',\n",
       " 728: u'moving',\n",
       " 729: u'similar',\n",
       " 730: u'straight',\n",
       " 731: u'romantic',\n",
       " 732: u'sets',\n",
       " 733: u'review',\n",
       " 734: u'falls',\n",
       " 735: u'oscar',\n",
       " 736: u'mystery',\n",
       " 737: u'enjoyable',\n",
       " 738: u'needs',\n",
       " 739: u'appears',\n",
       " 740: u'talk',\n",
       " 741: u'rock',\n",
       " 742: u'george',\n",
       " 743: u'giving',\n",
       " 744: u'eye',\n",
       " 745: u'richard',\n",
       " 746: u'within',\n",
       " 747: u'ten',\n",
       " 748: u'animation',\n",
       " 749: u'message',\n",
       " 750: u'theater',\n",
       " 751: u'near',\n",
       " 752: u'above',\n",
       " 753: u'dull',\n",
       " 754: u'nearly',\n",
       " 755: u'sequel',\n",
       " 756: u'theme',\n",
       " 757: u'points',\n",
       " 758: u\"'\",\n",
       " 759: u'stand',\n",
       " 760: u'mention',\n",
       " 761: u'lady',\n",
       " 762: u'bunch',\n",
       " 763: u'add',\n",
       " 764: u'feels',\n",
       " 765: u'herself',\n",
       " 766: u'release',\n",
       " 767: u'red',\n",
       " 768: u'team',\n",
       " 769: u'storyline',\n",
       " 770: u'surprised',\n",
       " 771: u'ways',\n",
       " 772: u'using',\n",
       " 773: u'named',\n",
       " 774: u\"haven't\",\n",
       " 775: u'lots',\n",
       " 776: u'easy',\n",
       " 777: u'fantastic',\n",
       " 778: u'begins',\n",
       " 779: u'actual',\n",
       " 780: u'working',\n",
       " 781: u'effort',\n",
       " 782: u'york',\n",
       " 783: u'die',\n",
       " 784: u'hate',\n",
       " 785: u'french',\n",
       " 786: u'minute',\n",
       " 787: u'tale',\n",
       " 788: u'clear',\n",
       " 789: u'stay',\n",
       " 790: u'9',\n",
       " 791: u'elements',\n",
       " 792: u'feature',\n",
       " 793: u'among',\n",
       " 794: u'follow',\n",
       " 795: u'comments',\n",
       " 796: u're',\n",
       " 797: u'viewers',\n",
       " 798: u'avoid',\n",
       " 799: u'sister',\n",
       " 800: u'showing',\n",
       " 801: u'typical',\n",
       " 802: u'editing',\n",
       " 803: u\"what's\",\n",
       " 804: u'famous',\n",
       " 805: u'tried',\n",
       " 806: u'sorry',\n",
       " 807: u'dialog',\n",
       " 808: u'check',\n",
       " 809: u'fall',\n",
       " 810: u'period',\n",
       " 811: u'season',\n",
       " 812: u'form',\n",
       " 813: u'certain',\n",
       " 814: u'filmed',\n",
       " 815: u'weak',\n",
       " 816: u'soundtrack',\n",
       " 817: u'means',\n",
       " 818: u'buy',\n",
       " 819: u'material',\n",
       " 820: u'somehow',\n",
       " 821: u'realistic',\n",
       " 822: u'figure',\n",
       " 823: u'crime',\n",
       " 824: u'doubt',\n",
       " 825: u'gone',\n",
       " 826: u'peter',\n",
       " 827: u'tom',\n",
       " 828: u'kept',\n",
       " 829: u'viewing',\n",
       " 830: u't',\n",
       " 831: u'general',\n",
       " 832: u'leads',\n",
       " 833: u'greatest',\n",
       " 834: u'space',\n",
       " 835: u'lame',\n",
       " 836: u'suspense',\n",
       " 837: u'dance',\n",
       " 838: u'imagine',\n",
       " 839: u'brought',\n",
       " 840: u'third',\n",
       " 841: u'atmosphere',\n",
       " 842: u'hear',\n",
       " 843: u'particular',\n",
       " 844: u'sequences',\n",
       " 845: u'whatever',\n",
       " 846: u'parents',\n",
       " 847: u'move',\n",
       " 848: u'lee',\n",
       " 849: u'indeed',\n",
       " 850: u'learn',\n",
       " 851: u'rent',\n",
       " 852: u'de',\n",
       " 853: u'eventually',\n",
       " 854: u'note',\n",
       " 855: u'deal',\n",
       " 856: u'average',\n",
       " 857: u'reviews',\n",
       " 858: u'wait',\n",
       " 859: u'forget',\n",
       " 860: u'japanese',\n",
       " 861: u'sexual',\n",
       " 862: u'poorly',\n",
       " 863: u'premise',\n",
       " 864: u'okay',\n",
       " 865: u'zombie',\n",
       " 866: u'surprise',\n",
       " 867: u'believable',\n",
       " 868: u'stage',\n",
       " 869: u'possibly',\n",
       " 870: u'sit',\n",
       " 871: u\"who's\",\n",
       " 872: u'decided',\n",
       " 873: u'expected',\n",
       " 874: u\"you've\",\n",
       " 875: u'subject',\n",
       " 876: u'nature',\n",
       " 877: u'became',\n",
       " 878: u'difficult',\n",
       " 879: u'free',\n",
       " 880: u'killing',\n",
       " 881: u'screenplay',\n",
       " 882: u'truth',\n",
       " 883: u'romance',\n",
       " 884: u'dr',\n",
       " 885: u'nor',\n",
       " 886: u'reading',\n",
       " 887: u'needed',\n",
       " 888: u'question',\n",
       " 889: u'leaves',\n",
       " 890: u'street',\n",
       " 891: u'20',\n",
       " 892: u'meets',\n",
       " 893: u'hot',\n",
       " 894: u'unless',\n",
       " 895: u'begin',\n",
       " 896: u'baby',\n",
       " 897: u'superb',\n",
       " 898: u'credits',\n",
       " 899: u'imdb',\n",
       " 900: u'otherwise',\n",
       " 901: u'write',\n",
       " 902: u'shame',\n",
       " 903: u\"let's\",\n",
       " 904: u'situation',\n",
       " 905: u'dramatic',\n",
       " 906: u'memorable',\n",
       " 907: u'directors',\n",
       " 908: u'earlier',\n",
       " 909: u'meet',\n",
       " 910: u'disney',\n",
       " 911: u'open',\n",
       " 912: u'dog',\n",
       " 913: u'badly',\n",
       " 914: u'joe',\n",
       " 915: u'male',\n",
       " 916: u'weird',\n",
       " 917: u'acted',\n",
       " 918: u'forced',\n",
       " 919: u'laughs',\n",
       " 920: u'sci',\n",
       " 921: u'emotional',\n",
       " 922: u'older',\n",
       " 923: u'realize',\n",
       " 924: u'fi',\n",
       " 925: u'dream',\n",
       " 926: u'society',\n",
       " 927: u'writers',\n",
       " 928: u'interested',\n",
       " 929: u'footage',\n",
       " 930: u'forward',\n",
       " 931: u'comment',\n",
       " 932: u'crazy',\n",
       " 933: u'deep',\n",
       " 934: u'sounds',\n",
       " 935: u'plus',\n",
       " 936: u'beauty',\n",
       " 937: u'whom',\n",
       " 938: u'america',\n",
       " 939: u'fantasy',\n",
       " 940: u'directing',\n",
       " 941: u'keeps',\n",
       " 942: u'ask',\n",
       " 943: u'development',\n",
       " 944: u'features',\n",
       " 945: u'air',\n",
       " 946: u'quickly',\n",
       " 947: u'mess',\n",
       " 948: u'creepy',\n",
       " 949: u'towards',\n",
       " 950: u'perfectly',\n",
       " 951: u'mark',\n",
       " 952: u'worked',\n",
       " 953: u'box',\n",
       " 954: u'cheesy',\n",
       " 955: u'unique',\n",
       " 956: u'setting',\n",
       " 957: u'hands',\n",
       " 958: u'plenty',\n",
       " 959: u'result',\n",
       " 960: u'previous',\n",
       " 961: u'brings',\n",
       " 962: u'effect',\n",
       " 963: u'e',\n",
       " 964: u'total',\n",
       " 965: u'personal',\n",
       " 966: u'incredibly',\n",
       " 967: u'rate',\n",
       " 968: u'fire',\n",
       " 969: u'monster',\n",
       " 970: u'business',\n",
       " 971: u'leading',\n",
       " 972: u'apart',\n",
       " 973: u'casting',\n",
       " 974: u'admit',\n",
       " 975: u'joke',\n",
       " 976: u'powerful',\n",
       " 977: u'appear',\n",
       " 978: u'background',\n",
       " 979: u'telling',\n",
       " 980: u'girlfriend',\n",
       " 981: u'meant',\n",
       " 982: u'christmas',\n",
       " 983: u'hardly',\n",
       " 984: u'present',\n",
       " 985: u'battle',\n",
       " 986: u'potential',\n",
       " 987: u'create',\n",
       " 988: u'bill',\n",
       " 989: u'break',\n",
       " 990: u'pay',\n",
       " 991: u'masterpiece',\n",
       " 992: u'gay',\n",
       " 993: u'political',\n",
       " 994: u'return',\n",
       " 995: u'dumb',\n",
       " 996: u'fails',\n",
       " 997: u'fighting',\n",
       " 998: u'various',\n",
       " 999: u'era',\n",
       " 1000: u'portrayed',\n",
       " ...}"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "colab_type": "code",
    "id": "NZ8xFV_mWoy_",
    "outputId": "7c3b0944-86fd-4a85-9291-3fcafa6f7d3e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   6,  346,  137,   11,    4, 2768,  295,   36, 7740,  725,    6,\n",
       "       3208,  273,   11,    4, 1513,   15, 1367,   35,  154,    2,  103,\n",
       "          2,  173,    7,   12,   36,  515, 3547,   94, 2547, 1722,    5,\n",
       "       3547,   36,  203,   30,  502,    8,  361,   12,    8,  989,  143,\n",
       "          4, 1172, 3404,   10,   10,  328, 1236,    9,    6,   55,  221,\n",
       "       2989,    5,  146,  165,  179,  770,   15,   50,  713,   53,  108,\n",
       "        448,   23,   12,   17,  225,   38,   76, 4397,   18,  183,    8,\n",
       "         81,   19,   12,   45, 1257,    8,  135,   15,    2,  166,    4,\n",
       "        118,    7,   45,    2,   17,  466,   45,    2,    4,   22,  115,\n",
       "        165,  764, 6075,    5, 1030,    8, 2973,   73,  469,  167, 2127,\n",
       "          2, 1568,    6,   87,  841,   18,    4,   22,    4,  192,   15,\n",
       "         91,    7,   12,  304,  273, 1004,    4, 1375, 1172, 2768,    2,\n",
       "         15,    4,   22,  764,   55, 5773,    5,   14, 4233, 7444,    4,\n",
       "       1375,  326,    7,    4, 4760, 1786,    8,  361, 1236,    8,  989,\n",
       "         46,    7,    4, 2768,   45,   55,  776,    8,   79,  496,   98,\n",
       "         45,  400,  301,   15,    4, 1859,    9,    4,  155,   15,   66,\n",
       "          2,   84,    5,   14,   22, 1534,   15,   17,    4,  167,    2,\n",
       "         15,   75,   70,  115,   66,   30,  252,    7,  618,   51,    9,\n",
       "       2161,    4, 3130,    5,   14, 1525,    8, 6584,   15,    2,  165,\n",
       "        127, 1921,    8,   30,  179, 2532,    4,   22,    9,  906,   18,\n",
       "          6,  176,    7, 1007, 1005,    4, 1375,  114,    4,  105,   26,\n",
       "         32,   55,  221,   11,   68,  205,   96,    5,    4,  192,   15,\n",
       "          4,  274,  410,  220,  304,   23,   94,  205,  109,    9,   55,\n",
       "         73,  224,  259, 3786,   15,    4,   22,  528, 1645,   34,    4,\n",
       "        130,  528,   30,  685,  345,   17,    4,  277,  199,  166,  281,\n",
       "          5, 1030,    8,   30,  179, 4442,  444,    2,    9,    6,  371,\n",
       "         87,  189,   22,    5,   31,    7,    4,  118,    7,    4, 2068,\n",
       "        545, 1178,  829], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets Decode and check for some train values.\n",
    "x_train[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "lJvSGO1uWxK9",
    "outputId": "21a7a4d6-4481-4469-8724-ebc3309b2158"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"a short while in the cell together they stumble upon a hiding place in the wall that contains an old <UNK> after <UNK> part of it they soon realise its magical powers and realise they may be able to use it to break through the prison walls br br black magic is a very interesting topic and i'm actually quite surprised that there aren't more films based on it as there's so much scope for things to do with it it's fair to say that <UNK> makes the best of it's <UNK> as despite it's <UNK> the film never actually feels restrained and manages to flow well throughout director eric <UNK> provides a great atmosphere for the film the fact that most of it takes place inside the central prison cell <UNK> that the film feels very claustrophobic and this immensely benefits the central idea of the prisoners wanting to use magic to break out of the cell it's very easy to get behind them it's often said that the unknown is the thing that really <UNK> people and this film proves that as the director <UNK> that we can never really be sure of exactly what is round the corner and this helps to ensure that <UNK> actually does manage to be quite frightening the film is memorable for a lot of reasons outside the central plot the characters are all very interesting in their own way and the fact that the book itself almost takes on its own character is very well done anyone worried that the film won't deliver by the end won't be disappointed either as the ending both makes sense and manages to be quite horrifying overall <UNK> is a truly great horror film and one of the best of the decade highly recommended viewing\""
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restore_original_text(x_train[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "colab_type": "code",
    "id": "_kosrj4tQZlD",
    "outputId": "1e350f4e-e452-478b-8232-e89b2b5e5dbe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    1,  591,  202,   14,   31,    6,  717,   10,   10,    2,\n",
       "          2,    5,    4,  360,    7,    4,  177, 5760,  394,  354,    4,\n",
       "        123,    9, 1035, 1035, 1035,   10,   10,   13,   92,  124,   89,\n",
       "        488, 7944,  100,   28, 1668,   14,   31,   23,   27, 7479,   29,\n",
       "        220,  468,    8,  124,   14,  286,  170,    8,  157,   46,    5,\n",
       "         27,  239,   16,  179,    2,   38,   32,   25, 7944,  451,  202,\n",
       "         14,    6,  717], dtype=int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets Decode and check for some test values.\n",
    "x_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "VJv1KoMnaGzq",
    "outputId": "246fac53-141c-4e96-c182-b816c1e660f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <START> please give this one a miss br br <UNK> <UNK> and the rest of the cast rendered terrible performances the show is flat flat flat br br i don't know how michael madison could have allowed this one on his plate he almost seemed to know this wasn't going to work out and his performance was quite <UNK> so all you madison fans give this a miss\""
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restore_original_text(x_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dybtUgUReCy8"
   },
   "source": [
    "## Build Keras Embedding Layer Model\n",
    "We can think of the Embedding layer as a dicionary that maps a index assigned to a word to a word vector. This layer is very flexible and can be used in a few ways:\n",
    "\n",
    "* The embedding layer can be used at the start of a larger deep learning model. \n",
    "* Also we could load pre-train word embeddings into the embedding layer when we create our model.\n",
    "* Use the embedding layer to train our own word2vec models.\n",
    "\n",
    "The keras embedding layer doesn't require us to onehot encode our words, instead we have to give each word a unqiue intger number as an id. For the imdb dataset we've loaded this has already been done, but if this wasn't the case we could use sklearn [LabelEncoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A5OLM4eBeCy9"
   },
   "outputs": [],
   "source": [
    "#4.Build a Sequential Model using Keras for Sentiment Classification task. (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "colab_type": "code",
    "id": "TxNDNhrseCzA",
    "outputId": "44a4695b-1b3e-4cdc-c370-869e9b1fe9c3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0308 09:50:23.652095 140235238573952 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0308 09:50:23.677509 140235238573952 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling __init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "#from keras.layers import LSTM, Dense, Dropout, Embedding, Masking, Bidirectional, GlobalAveragePooling1D\n",
    "\n",
    "tf.set_random_seed(100)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, 16))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "\n",
    "# Dropout for regularization\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(32, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(16, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 398
    },
    "colab_type": "code",
    "id": "L3CSVVPPeCzD",
    "outputId": "f40142ba-237f-4ab4-b8c6-b959286f615c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 163,713\n",
      "Trainable params: 163,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "VmIEgr0mguoG",
    "outputId": "45b20afe-3c03-421d-816c-9e02abe46ecf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0308 09:50:23.794552 140235238573952 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 728
    },
    "colab_type": "code",
    "id": "rPRBklb0g3GK",
    "outputId": "0f4c6bbb-ef97-48db-816b-e356956d208d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/20\n",
      "25000/25000 [==============================] - 1s 34us/sample - loss: 0.6913 - acc: 0.5565 - val_loss: 0.6826 - val_acc: 0.6524\n",
      "Epoch 2/20\n",
      "25000/25000 [==============================] - 1s 21us/sample - loss: 0.6145 - acc: 0.7559 - val_loss: 0.4884 - val_acc: 0.8256\n",
      "Epoch 3/20\n",
      "25000/25000 [==============================] - 1s 20us/sample - loss: 0.3777 - acc: 0.8562 - val_loss: 0.3237 - val_acc: 0.8683\n",
      "Epoch 4/20\n",
      "25000/25000 [==============================] - 1s 20us/sample - loss: 0.2669 - acc: 0.8996 - val_loss: 0.3019 - val_acc: 0.8763\n",
      "Epoch 5/20\n",
      "25000/25000 [==============================] - 1s 20us/sample - loss: 0.2187 - acc: 0.9202 - val_loss: 0.2963 - val_acc: 0.8809\n",
      "Epoch 6/20\n",
      "25000/25000 [==============================] - 1s 21us/sample - loss: 0.1857 - acc: 0.9358 - val_loss: 0.3027 - val_acc: 0.8808\n",
      "Epoch 7/20\n",
      "25000/25000 [==============================] - 1s 20us/sample - loss: 0.1632 - acc: 0.9471 - val_loss: 0.3087 - val_acc: 0.8818\n",
      "Epoch 8/20\n",
      "25000/25000 [==============================] - 1s 20us/sample - loss: 0.1446 - acc: 0.9541 - val_loss: 0.3245 - val_acc: 0.8794\n",
      "Epoch 9/20\n",
      "25000/25000 [==============================] - 1s 20us/sample - loss: 0.1257 - acc: 0.9616 - val_loss: 0.3424 - val_acc: 0.8762\n",
      "Epoch 10/20\n",
      "25000/25000 [==============================] - 1s 20us/sample - loss: 0.1139 - acc: 0.9670 - val_loss: 0.3672 - val_acc: 0.8735\n",
      "Epoch 11/20\n",
      "25000/25000 [==============================] - 1s 20us/sample - loss: 0.1000 - acc: 0.9732 - val_loss: 0.3901 - val_acc: 0.8694\n",
      "Epoch 12/20\n",
      "25000/25000 [==============================] - 1s 21us/sample - loss: 0.0882 - acc: 0.9780 - val_loss: 0.4169 - val_acc: 0.8668\n",
      "Epoch 13/20\n",
      "25000/25000 [==============================] - 1s 20us/sample - loss: 0.0833 - acc: 0.9796 - val_loss: 0.4301 - val_acc: 0.8674\n",
      "Epoch 14/20\n",
      "25000/25000 [==============================] - 1s 20us/sample - loss: 0.0722 - acc: 0.9834 - val_loss: 0.4502 - val_acc: 0.8652\n",
      "Epoch 15/20\n",
      "25000/25000 [==============================] - 0s 20us/sample - loss: 0.0664 - acc: 0.9862 - val_loss: 0.4753 - val_acc: 0.8630\n",
      "Epoch 16/20\n",
      "25000/25000 [==============================] - 1s 20us/sample - loss: 0.0630 - acc: 0.9865 - val_loss: 0.5053 - val_acc: 0.8612\n",
      "Epoch 17/20\n",
      "25000/25000 [==============================] - 1s 20us/sample - loss: 0.0575 - acc: 0.9878 - val_loss: 0.5272 - val_acc: 0.8589\n",
      "Epoch 18/20\n",
      "25000/25000 [==============================] - 1s 21us/sample - loss: 0.0534 - acc: 0.9888 - val_loss: 0.5449 - val_acc: 0.8586\n",
      "Epoch 19/20\n",
      "25000/25000 [==============================] - 1s 20us/sample - loss: 0.0474 - acc: 0.9908 - val_loss: 0.5580 - val_acc: 0.8573\n",
      "Epoch 20/20\n",
      "25000/25000 [==============================] - 1s 21us/sample - loss: 0.0453 - acc: 0.9915 - val_loss: 0.5787 - val_acc: 0.8558\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,\n",
    "                    y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dZNin3_VhGLw"
   },
   "outputs": [],
   "source": [
    "#5.Report the Accuracy of the model. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "gDLdhKFIhQrc",
    "outputId": "c1339548-e31e-4080-f0e9-306b85fc7655"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance: Log Loss and Accuracy on train data\n",
      "25000/25000 [==============================] - 2s 66us/sample - loss: 0.0348 - acc: 0.9942\n",
      "[0.034775503547303376, 0.99416]\n",
      "\n",
      "Model Performance: Log Loss and Accuracy on validation data\n",
      "25000/25000 [==============================] - 2s 67us/sample - loss: 0.5787 - acc: 0.8558\n",
      "[0.5787091667998582, 0.85584]\n"
     ]
    }
   ],
   "source": [
    "print('\\nModel Performance: Log Loss and Accuracy on train data')\n",
    "print(model.evaluate(x_train, y_train, batch_size = 20))\n",
    "print('\\nModel Performance: Log Loss and Accuracy on validation data')\n",
    "print(model.evaluate(x_test, y_test, batch_size = 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "K48GSoSyhmt-",
    "outputId": "547b9bc2-d5b7-4892-b7bc-8ccd8e9fdaae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('right : ', 89)\n",
      "('mistake : ', 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>x_test_original_text</th>\n",
       "      <th>probability</th>\n",
       "      <th>pred_class</th>\n",
       "      <th>y_test</th>\n",
       "      <th>is_fail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20710</td>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0.015804</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11779</td>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0.026435</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6149</td>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0.004258</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21575</td>\n",
       "      <td>to pointless arty detail the important matters...</td>\n",
       "      <td>0.001598</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5802</td>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8751</td>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17117</td>\n",
       "      <td>each other &lt;UNK&gt; &lt;UNK&gt; as they become increasi...</td>\n",
       "      <td>0.999753</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2926</td>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0.092043</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>957</td>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0.999001</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14346</td>\n",
       "      <td>men looked handsome and &lt;UNK&gt; br br is this a ...</td>\n",
       "      <td>0.997646</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15513</td>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0.997858</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15207</td>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;START&gt; &lt;U...</td>\n",
       "      <td>0.156156</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>17913</td>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0.005372</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>17651</td>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0.052534</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>17408</td>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0.994764</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5759</td>\n",
       "      <td>cinematography &lt;UNK&gt; nut is one for the ages a...</td>\n",
       "      <td>0.996399</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>983</td>\n",
       "      <td>before leaving to montana when they stopped at...</td>\n",
       "      <td>0.968276</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6334</td>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0.996295</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17483</td>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0.997852</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10430</td>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0.003693</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>18843</td>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0.998525</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>16257</td>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0.997030</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22105</td>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0.990957</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1366</td>\n",
       "      <td>i found this movie on a &lt;UNK&gt; sale &lt;UNK&gt; for 3...</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10896</td>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0.004458</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>19878</td>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>16490</td>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0.916594</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>15494</td>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0.989758</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3053</td>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0.997224</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1542</td>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;STA...</td>\n",
       "      <td>0.001155</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>24155</td>\n",
       "      <td>&lt;UNK&gt; remake we were almost unable to keep fro...</td>\n",
       "      <td>0.081724</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>23495</td>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>17472</td>\n",
       "      <td>mute witness starring a cast of &lt;UNK&gt; except a...</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>3973</td>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0.997980</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>10926</td>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0.008896</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>4448</td>\n",
       "      <td>a script that never really delivers the amount...</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>6768</td>\n",
       "      <td>into that nasty series post alien 3 habit of &lt;...</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>21264</td>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0.996853</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>9696</td>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0.006025</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>11456</td>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0.991086</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>5548</td>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0.007719</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>6790</td>\n",
       "      <td>how badly they'd got me on this one this is a ...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>22056</td>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0.996722</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>9228</td>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0.004014</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>22792</td>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0.991011</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>6677</td>\n",
       "      <td>of the swamp making it at times far more scary...</td>\n",
       "      <td>0.005837</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>13074</td>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0.997229</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>5383</td>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0.008204</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>24137</td>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>9311</td>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0.004669</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>18590</td>\n",
       "      <td>because of the subject matter and there were n...</td>\n",
       "      <td>0.359221</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>10002</td>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>12871</td>\n",
       "      <td>they're all miscast an &lt;UNK&gt; of amateur go on ...</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>10483</td>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>17560</td>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0.988558</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>12812</td>\n",
       "      <td>man mr garfield is blamed when the manager die...</td>\n",
       "      <td>0.994557</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>9</td>\n",
       "      <td>expecting anything else from burton and the co...</td>\n",
       "      <td>0.999905</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>3998</td>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0.981378</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>8474</td>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0.976918</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>20202</td>\n",
       "      <td>&lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD&gt; &lt;PAD...</td>\n",
       "      <td>0.998900</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                               x_test_original_text  ...    y_test is_fail\n",
       "0   20710  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...  ...  negative        \n",
       "1   11779  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...  ...  negative        \n",
       "2    6149  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...  ...  negative        \n",
       "3   21575  to pointless arty detail the important matters...  ...  negative        \n",
       "4    5802  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...  ...  negative        \n",
       "5    8751  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...  ...  negative        \n",
       "6   17117  each other <UNK> <UNK> as they become increasi...  ...  positive        \n",
       "7    2926  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...  ...  negative        \n",
       "8     957  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...  ...  positive        \n",
       "9   14346  men looked handsome and <UNK> br br is this a ...  ...  negative    Fail\n",
       "10  15513  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...  ...  positive        \n",
       "11  15207  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <START> <U...  ...  negative        \n",
       "12  17913  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...  ...  negative        \n",
       "13  17651  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...  ...  negative        \n",
       "14  17408  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...  ...  positive        \n",
       "15   5759  cinematography <UNK> nut is one for the ages a...  ...  positive        \n",
       "16    983  before leaving to montana when they stopped at...  ...  negative    Fail\n",
       "17   6334  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...  ...  positive        \n",
       "18  17483  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...  ...  positive        \n",
       "19  10430  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...  ...  negative        \n",
       "20  18843  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...  ...  positive        \n",
       "21  16257  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...  ...  positive        \n",
       "22  22105  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...  ...  positive        \n",
       "23   1366  i found this movie on a <UNK> sale <UNK> for 3...  ...  negative        \n",
       "24  10896  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...  ...  negative        \n",
       "25  19878  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...  ...  negative        \n",
       "26  16490  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...  ...  positive        \n",
       "27  15494  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...  ...  positive        \n",
       "28   3053  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...  ...  positive        \n",
       "29   1542  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <STA...  ...  negative        \n",
       "..    ...                                                ...  ...       ...     ...\n",
       "70  24155  <UNK> remake we were almost unable to keep fro...  ...  positive    Fail\n",
       "71  23495  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...  ...  negative        \n",
       "72  17472  mute witness starring a cast of <UNK> except a...  ...  positive    Fail\n",
       "73   3973  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...  ...  positive        \n",
       "74  10926  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...  ...  negative        \n",
       "75   4448  a script that never really delivers the amount...  ...  negative        \n",
       "76   6768  into that nasty series post alien 3 habit of <...  ...  negative        \n",
       "77  21264  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...  ...  positive        \n",
       "78   9696  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...  ...  negative        \n",
       "79  11456  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...  ...  positive        \n",
       "80   5548  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...  ...  negative        \n",
       "81   6790  how badly they'd got me on this one this is a ...  ...  negative        \n",
       "82  22056  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...  ...  positive        \n",
       "83   9228  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...  ...  positive    Fail\n",
       "84  22792  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...  ...  positive        \n",
       "85   6677  of the swamp making it at times far more scary...  ...  positive    Fail\n",
       "86  13074  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...  ...  negative    Fail\n",
       "87   5383  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...  ...  negative        \n",
       "88  24137  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...  ...  positive        \n",
       "89   9311  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...  ...  negative        \n",
       "90  18590  because of the subject matter and there were n...  ...  positive    Fail\n",
       "91  10002  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...  ...  negative        \n",
       "92  12871  they're all miscast an <UNK> of amateur go on ...  ...  negative        \n",
       "93  10483  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...  ...  negative        \n",
       "94  17560  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...  ...  positive        \n",
       "95  12812  man mr garfield is blamed when the manager die...  ...  positive        \n",
       "96      9  expecting anything else from burton and the co...  ...  positive        \n",
       "97   3998  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...  ...  positive        \n",
       "98   8474  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...  ...  negative    Fail\n",
       "99  20202  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD...  ...  positive        \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "PREDICT\n",
    "'''\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "original_x_test = x_test\n",
    "\n",
    "def restore_original_text(imdb_x_array):\n",
    "    return (' '.join(id_to_word[id] for id in imdb_x_array ))\n",
    "\n",
    "def imdb_class_to_str(imdb_class):\n",
    "    if imdb_class == 0:\n",
    "        return 'negative'\n",
    "    return 'positive'\n",
    "\n",
    "right = 0\n",
    "mistake = 0\n",
    "\n",
    "index_list = []\n",
    "original_text_list = []\n",
    "pred_prob_list = []\n",
    "pred_class_list = []\n",
    "y_test_list = []\n",
    "fail_str_list = []\n",
    "\n",
    "for i in range(100):\n",
    "    index = random.randint(0, len(x_test))\n",
    "    \n",
    "    pred_prob = model.predict(x_test[index:(index+1)])[0][0] \n",
    "    pred_class = model.predict_classes(x_test[index:(index+1)])[0][0]\n",
    "    \n",
    "    '''\n",
    "    print('pred_prod:', pred_prod)\n",
    "    print('pred_class:', pred_class)\n",
    "    print('y_test[index] :', y_test[index])\n",
    "    '''\n",
    "    fail_str = '' \n",
    "    \n",
    "    if y_test[index] == pred_class:\n",
    "        right += 1\n",
    "    else:\n",
    "        mistake += 1\n",
    "        fail_str = 'Fail'\n",
    "        \n",
    "    original_text = restore_original_text(original_x_test[index])\n",
    "\n",
    "    index_list.append(index)\n",
    "    original_text_list.append(original_text)\n",
    "    pred_prob_list.append(pred_prob)\n",
    "    pred_class_list.append(imdb_class_to_str(pred_class))\n",
    "    y_test_list.append(imdb_class_to_str(y_test[index]))\n",
    "    fail_str_list.append(fail_str)\n",
    "\n",
    "print(\"right : \", right)\n",
    "print(\"mistake : \", mistake)\n",
    "\n",
    "df = pd.DataFrame({'index': index_list, \n",
    "                   'x_test_original_text': original_text_list, \n",
    "                   'probability': pred_prob_list, \n",
    "                   'pred_class': pred_class_list,\n",
    "                   'y_test': y_test_list,\n",
    "                   'is_fail': fail_str_list\n",
    "                  })\n",
    "\n",
    "df[['index', 'x_test_original_text','probability','pred_class','y_test','is_fail']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Igq8Qm8GeCzG"
   },
   "source": [
    "## Retrive the output of each layer in keras for a given single test sample from the trained model you built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0AqOnLa2eCzH"
   },
   "outputs": [],
   "source": [
    "#6.Retrive the output of each layer in keras for a given single test sample from the trained model you built. (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lMo42EfKkTAq"
   },
   "outputs": [],
   "source": [
    "from keras import backend as k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "id": "-dUDSg7VeCzM",
    "outputId": "66d87e44-9652-48f4-d228-6e0ea6be864f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0308 09:54:35.226464 140235238573952 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0308 09:54:35.227505 140235238573952 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Define function to get output of all the layers in the model for specific test input\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.tables_initializer())\n",
    "\n",
    "    def getLayerOutput(layer):\n",
    "        get_Layer_Output = k.function([model.layers[0].input], [layer.output])\n",
    "        return get_Layer_Output([x_test[0:1,]])[0]\n",
    "    \n",
    "    layer_output = []\n",
    "    \n",
    "    for layer in model.layers:\n",
    "        layer_output.append(getLayerOutput(layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Tskt_1npeCzP",
    "outputId": "8c3d18d9-d78b-4b4e-cd6c-b3b2bedd64d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the count of ouput. It should be equal to the number of layers\n",
    "len(layer_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 988
    },
    "colab_type": "code",
    "id": "9E5TBJM4kadq",
    "outputId": "170e589d-039f-4858-9479-b23b193234dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[-0.00458338,  0.04823485,  0.02042371, ...,  0.03888449,\n",
       "          -0.01751048,  0.00803411],\n",
       "         [-0.00458338,  0.04823485,  0.02042371, ...,  0.03888449,\n",
       "          -0.01751048,  0.00803411],\n",
       "         [-0.00458338,  0.04823485,  0.02042371, ...,  0.03888449,\n",
       "          -0.01751048,  0.00803411],\n",
       "         ...,\n",
       "         [ 0.04579827, -0.00981784, -0.02570111, ...,  0.02962463,\n",
       "          -0.04944974, -0.02211731],\n",
       "         [ 0.04799093, -0.03852631,  0.04156684, ..., -0.01586529,\n",
       "          -0.03594899,  0.03170117],\n",
       "         [-0.00144356,  0.04378692,  0.00424818, ..., -0.01755618,\n",
       "          -0.0028383 , -0.03627374]]], dtype=float32),\n",
       " array([[-0.00301607,  0.03692188,  0.01417997, -0.01547567, -0.01877829,\n",
       "          0.0399677 , -0.0034747 , -0.01725606,  0.0074258 , -0.00178651,\n",
       "          0.01001158, -0.00320485, -0.02594487,  0.0301198 , -0.01571364,\n",
       "          0.00830047]], dtype=float32),\n",
       " array([[0.        , 0.        , 0.01101602, 0.00524644, 0.        ,\n",
       "         0.        , 0.        , 0.01019217, 0.        , 0.        ,\n",
       "         0.01768403, 0.01140995, 0.        , 0.00893559, 0.00641206,\n",
       "         0.01021314, 0.        , 0.00821325, 0.        , 0.0034901 ,\n",
       "         0.        , 0.        , 0.        , 0.02163267, 0.00107495,\n",
       "         0.        , 0.02565341, 0.02123948, 0.02182533, 0.00820519,\n",
       "         0.00686321, 0.00561919, 0.        , 0.        , 0.        ,\n",
       "         0.0016309 , 0.        , 0.        , 0.00802844, 0.        ,\n",
       "         0.00860214, 0.        , 0.0046777 , 0.011356  , 0.02129352,\n",
       "         0.01169974, 0.00418537, 0.        , 0.        , 0.00566915,\n",
       "         0.        , 0.00548731, 0.00245883, 0.00457622, 0.00041493,\n",
       "         0.01304827, 0.01613861, 0.00882609, 0.        , 0.        ,\n",
       "         0.00266701, 0.        , 0.00302794, 0.00224574]], dtype=float32),\n",
       " array([[0.        , 0.        , 0.01101602, 0.00524644, 0.        ,\n",
       "         0.        , 0.        , 0.01019217, 0.        , 0.        ,\n",
       "         0.01768403, 0.01140995, 0.        , 0.00893559, 0.00641206,\n",
       "         0.01021314, 0.        , 0.00821325, 0.        , 0.0034901 ,\n",
       "         0.        , 0.        , 0.        , 0.02163267, 0.00107495,\n",
       "         0.        , 0.02565341, 0.02123948, 0.02182533, 0.00820519,\n",
       "         0.00686321, 0.00561919, 0.        , 0.        , 0.        ,\n",
       "         0.0016309 , 0.        , 0.        , 0.00802844, 0.        ,\n",
       "         0.00860214, 0.        , 0.0046777 , 0.011356  , 0.02129352,\n",
       "         0.01169974, 0.00418537, 0.        , 0.        , 0.00566915,\n",
       "         0.        , 0.00548731, 0.00245883, 0.00457622, 0.00041493,\n",
       "         0.01304827, 0.01613861, 0.00882609, 0.        , 0.        ,\n",
       "         0.00266701, 0.        , 0.00302794, 0.00224574]], dtype=float32),\n",
       " array([[0.        , 0.        , 0.        , 0.00779984, 0.0023925 ,\n",
       "         0.00166397, 0.        , 0.0151292 , 0.00497129, 0.        ,\n",
       "         0.00219359, 0.        , 0.        , 0.00514197, 0.        ,\n",
       "         0.00231733, 0.00856898, 0.        , 0.00226037, 0.        ,\n",
       "         0.        , 0.        , 0.00035003, 0.        , 0.        ,\n",
       "         0.00389647, 0.        , 0.00657898, 0.01057073, 0.00790536,\n",
       "         0.        , 0.01315206]], dtype=float32),\n",
       " array([[8.7450547e-03, 6.3412949e-03, 8.6541241e-03, 0.0000000e+00,\n",
       "         0.0000000e+00, 1.4547375e-03, 0.0000000e+00, 9.2097502e-03,\n",
       "         7.6373373e-03, 1.1102702e-02, 2.7083112e-03, 2.9122224e-05,\n",
       "         5.3746295e-03, 0.0000000e+00, 0.0000000e+00, 3.2838911e-04]],\n",
       "       dtype=float32),\n",
       " array([[0.4982353]], dtype=float32)]"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check all the outputs\n",
    "layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242
    },
    "colab_type": "code",
    "id": "7Yif4NVwkf0i",
    "outputId": "17cc29dd-50d2-4fa0-c44c-078b6b04402b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.01101602, 0.00524644, 0.        ,\n",
       "        0.        , 0.        , 0.01019217, 0.        , 0.        ,\n",
       "        0.01768403, 0.01140995, 0.        , 0.00893559, 0.00641206,\n",
       "        0.01021314, 0.        , 0.00821325, 0.        , 0.0034901 ,\n",
       "        0.        , 0.        , 0.        , 0.02163267, 0.00107495,\n",
       "        0.        , 0.02565341, 0.02123948, 0.02182533, 0.00820519,\n",
       "        0.00686321, 0.00561919, 0.        , 0.        , 0.        ,\n",
       "        0.0016309 , 0.        , 0.        , 0.00802844, 0.        ,\n",
       "        0.00860214, 0.        , 0.0046777 , 0.011356  , 0.02129352,\n",
       "        0.01169974, 0.00418537, 0.        , 0.        , 0.00566915,\n",
       "        0.        , 0.00548731, 0.00245883, 0.00457622, 0.00041493,\n",
       "        0.01304827, 0.01613861, 0.00882609, 0.        , 0.        ,\n",
       "        0.00266701, 0.        , 0.00302794, 0.00224574]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the specific layer output\n",
    "layer_output[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZbPrVRHjkg6P"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SeqNLP_Project1_Questions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
